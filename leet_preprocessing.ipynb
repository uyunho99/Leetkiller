{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSAT data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF2Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', '24년 언어이해.pdf', 'README.md']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "file_path = os.path.join(os.getcwd(), 'Data')\n",
    "file_name = os.listdir(file_path)\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_psat_text(file_name):\n",
    "    leet_text = []\n",
    "    for file in file_name:\n",
    "        if file.endswith('.pdf'):\n",
    "            pdf = PdfReader(os.path.join(file_path, file))\n",
    "            text = ''\n",
    "            \n",
    "            for i, page in enumerate(pdf.pages):\n",
    "                text += page.extract_text()\n",
    "            \n",
    "            text = text.replace(' .', '.')\n",
    "            text = text.replace(' , ', ', ')\n",
    "            text = text.replace(' ? ', '? ')\n",
    "            text = re.sub(r\"(\\d+)\\.\", r\"\\1. \", text)\n",
    "            text = re.sub(r\"(①)|(②)|(③)|(④)|(⑤)\", r\"\\1\\2\\3\\4\\5 \", text)\n",
    "\n",
    "            leet_text.append(text)\n",
    "\n",
    "    return leet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "leet_text = clean_psat_text(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./leet_clean.txt', 'w') as f:\n",
    "    f.write(leet_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './leett_clean.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jiwon/programming/ML/Deep daiv/Leetkiller/leet_preprocessing.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jiwon/programming/ML/Deep%20daiv/Leetkiller/leet_preprocessing.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39m./leett_clean.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiwon/programming/ML/Deep%20daiv/Leetkiller/leet_preprocessing.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     psat_text \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/milab/lib/python3.10/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './leett_clean.txt'"
     ]
    }
   ],
   "source": [
    "with open(\"./leett_clean.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    psat_text = f.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('선된  효과를  나타낸다. 다음으로  정부는  50만원의  지원금을   \\n'\n",
      " '지불하므로  정부 계정에  비용으로  50만 원이 기입된다. 이때  \\n'\n",
      " '사회성과는  두 이해관계자의  비용과  편익을  합산한  순편익으로   \\n'\n",
      " '그 측정값은  100만 원이다.  \\n'\n",
      " '<그림>  \\n'\n",
      " ' 사회 문제 해결 활동과  관련한  편익과  비용을  실제로  측정하는   \\n'\n",
      " '데는 한계도  적지 않다. 그렇지만  그 편익을  화폐 단위로  환산하고  화폐화된  성과에  대한 평가를  \\n'\n",
      " '토대로  기존 이해관계자들을  통해  \\n'\n",
      " \"회수되지  못한 부분에  대한 금전적  보상, 곧 '사회성과  보상'이  \\n\"\n",
      " '다양한  수단들로  활성화된다면, 사회적  가치를  달성하는  활동들은   \\n'\n",
      " '가격을  본격적으로  부여받게  된다. 이 과정에서  기업과  비영리조직   \\n'\n",
      " '으로 더 많은 자금이  유입되고, 이들 조직이  효율적인  경영을  통해 더 높은 성과를  거두도록  동\\n'\n",
      " '기가 부여되며, 가격과  사회의  가치 규범도  다시 정렬될  것이다. 이러한  흐름은  오늘날  사회공헌\\n'\n",
      " '채권  \\n'\n",
      " '이나 임팩트투자  등으로  구체화되고  있다.  \\n'\n",
      " ' \\n'\n",
      " '13.  윗글에  대한 이해로  가장 적절한  것은?  \\n'\n",
      " \"①  '객관적  가치론 '은 가격에  의한 가치 규범의  변화에  대해 비판적   \\n\"\n",
      " '입장을  취할 것이다.  \\n'\n",
      " \"②  '주관적  가치론 '은 소비자의  욕구를  중시한  결과 공급자의  비용을   \\n\"\n",
      " '부차적인  문제로  취급할  것이다. \\n'\n",
      " \"③  '사회학적  관점'은 가치의  문제를  사람들의  욕구 충족이라는   \\n\"\n",
      " '측면에서  판단할  것이다.  \\n'\n",
      " \"④  '경제학적  관점'은 가치와  가격의  괴리 현상이  존재하지  않는다고   \\n\"\n",
      " '볼 것이다. \\n'\n",
      " \"⑤  취약계층을  고용하는  기업에  제공되는  고용지원금은  '외부성 '을  \\n\"\n",
      " \"강화해  '사회적  가치'를 제고할  것이다.   \\n\"\n",
      " '14.  사회성과와  관련한  다음의  추론 중 가장 적절한  것은?  \\n'\n",
      " \"①  '사회학적  관점'에서는  사회성과  측정이  사회구성원들이  중요시   \\n\"\n",
      " '하는 가치 규범을  반영할  수 없다고  여겨 사회성과  측정에   \\n'\n",
      " '기초한  사회적  가치 촉진 정책에  반대할  것이다.  \\n'\n",
      " '②  사회성과  보상이  사회적  가치 제고라는  본연의  목적에  충실하기   \\n'\n",
      " '위해서는  화폐화된  성과로  측정할  수 없는 편익도  평가할  수  \\n'\n",
      " '있는 보완책이  필요할  것이다.  \\n'\n",
      " \"③  '경제학적  관점에서는  사회성과  보상이  가격기구에  영향을  주지  \\n\"\n",
      " '않으면서  사회 문제를  해결하려는  시도이므로  사회성과  측정에   \\n'\n",
      " '찬성할  것이다.  \\n'\n",
      " '④  영리기업은  기업 활동의  결과로  발생한  이윤을  주주에게  배당  \\n'\n",
      " '하므로  사회성과  보상의  대상이  될 수 없을 것이다.  \\n'\n",
      " '⑤  정부 지원금은  기업의  사회적  가치 창출에  대한 보상의  성격이   \\n'\n",
      " '있으므로  사회성과  보상에  포함되어야  할 것이다.  \\n'\n",
      " ' \\n'\n",
      " '15.  윗글을  바탕으로  <보기>의 병원 활동을  설명한  것으로  적절하지   \\n'\n",
      " '않은 것은?  \\n'\n",
      " '<보기>  \\n'\n",
      " 'A병원은  2021년에 취약계층의  삶의 질 개선을  목적으로,  \\n'\n",
      " '일반 환자에게  10만 원에 제공하는  진료 서비스를  지역 거주  \\n'\n",
      " '취약계층 노인들에게는  회당 2만 원을 받고 총 100회를 제공  \\n'\n",
      " '하였다. 이때 지방자치단체는  회당 3만 원을 지원하였다. 한편,  \\n'\n",
      " '2022년에는  이 병원의  사회 공헌 활동이  널리 알려지면서   \\n'\n",
      " '지역의  뜻있는  주민들과  기업들도  동참해, 각각 회당 1만 원과 3만 원의 후원금을  지원했고, 이 \\n'\n",
      " '병원의  취약계층  노인 대상  \\n'\n",
      " '진료 서비스는  총 150회로 늘어났다. (단, 다른 조건에는  변화가   \\n'\n",
      " '없다.)  \\n'\n",
      " '①  2022년에 취약계층  노인들이  이 병원을  통해 얻은 편익은  전년  \\n'\n",
      " '도에 비해 500만 원 증가했다.  \\n'\n",
      " '②  2022년에 이 병원이  취약계층  노인을  위해 창출한  편익 중 가격  \\n'\n",
      " '기구를  통해 그 비용을  회수한  금액은  전년도에  비해 100만 원 증가했다.  \\n'\n",
      " '③  2021년부터  2년 동안 ')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(psat_text[0][18000:20000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- '2023년도 국가공무원 5급 공채 등 필기시험 언어논리영역 가책형 n쪽' 삭제\n",
    "- `text = re.sub(r\"(\\d+)\\.\", r\"\\1. \", text)`: 1~9만 가능, 여기 조건에 숫자 더 늘려야함\n",
    "\n",
    "- 7번: \\ue0ac -> π"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split by problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def search_multi_questions(text):\n",
    "    \n",
    "    matches = re.findall(r'\\[([0-9]+)~([0-9]+)\\]', text)\n",
    "    \n",
    "    q_nums = []\n",
    "    for match in matches:\n",
    "        a, b = int(match[0]), int(match[1])\n",
    "        q_nums.append((f\"[{a}~{b}]\", list(range(a, b+1))))\n",
    "    \n",
    "    return q_nums\n",
    "\n",
    "def split_psat_questions(content):\n",
    "    \n",
    "    question_pattern = re.compile(r'(\\d+\\.\\s[^?]*\\?)')\n",
    "    \n",
    "    chunks = re.split(question_pattern, content)\n",
    "    chunks = [chunk for chunk in chunks if chunk.strip()]\n",
    "\n",
    "    final_chunks = []\n",
    "    cache = [None] * len(chunks)\n",
    "    \n",
    "    q_nums = search_multi_questions(content)\n",
    "\n",
    "    for q_num in q_nums:\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            if q_num[0] in chunk:\n",
    "                key_index = chunk.find(q_num[0])\n",
    "                next_text = chunk[key_index:].strip()\n",
    "                chunks[i] = chunk[:key_index].strip()\n",
    "                cleaned_text = next_text.replace(q_num[0], \"\").replace(\"다음 글을 읽고 물음에 답하시오.\", \"\").strip()\n",
    "                for num in q_num[1]:\n",
    "                    cache[(2*num)-1] = cleaned_text\n",
    "                break\n",
    "    print(cache)\n",
    "    for i in range(0, len(chunks), 2):\n",
    "        question = chunks[i]\n",
    "        problems = chunks[i+1]\n",
    "        if cache[i+1]:\n",
    "            problems = (cache[i+1] if cache[i+1] else \"\") + \" \" + problems\n",
    "        final_chunks.append(question + \" \" + problems)\n",
    "    \n",
    "    return final_chunks, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jiwon/programming/ML/Deep daiv/Leetkiller/leet_preprocessing.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jiwon/programming/ML/Deep%20daiv/Leetkiller/leet_preprocessing.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m psat_questions, cache \u001b[39m=\u001b[39m split_psat_questions(leet_text)\n",
      "\u001b[1;32m/Users/jiwon/programming/ML/Deep daiv/Leetkiller/leet_preprocessing.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiwon/programming/ML/Deep%20daiv/Leetkiller/leet_preprocessing.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msplit_psat_questions\u001b[39m(content):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiwon/programming/ML/Deep%20daiv/Leetkiller/leet_preprocessing.ipynb#X33sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     question_pattern \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mcompile(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m(\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms[^?]*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m?)\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiwon/programming/ML/Deep%20daiv/Leetkiller/leet_preprocessing.ipynb#X33sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     chunks \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39;49msplit(question_pattern, content)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiwon/programming/ML/Deep%20daiv/Leetkiller/leet_preprocessing.ipynb#X33sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     chunks \u001b[39m=\u001b[39m [chunk \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m chunks \u001b[39mif\u001b[39;00m chunk\u001b[39m.\u001b[39mstrip()]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiwon/programming/ML/Deep%20daiv/Leetkiller/leet_preprocessing.ipynb#X33sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     final_chunks \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/milab/lib/python3.10/re.py:230\u001b[0m, in \u001b[0;36msplit\u001b[0;34m(pattern, string, maxsplit, flags)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msplit\u001b[39m(pattern, string, maxsplit\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m    223\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Split the source string by the occurrences of the pattern,\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[39m    returning a list containing the resulting substrings.  If\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[39m    capturing parentheses are used in pattern, then the text of all\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39m    and the remainder of the string is returned as the final element\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[39m    of the list.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m     \u001b[39mreturn\u001b[39;00m _compile(pattern, flags)\u001b[39m.\u001b[39;49msplit(string, maxsplit)\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "psat_questions, cache = split_psat_questions(leet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cache' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jiwon/programming/ML/Deep daiv/Leetkiller/leet_preprocessing.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jiwon/programming/ML/Deep%20daiv/Leetkiller/leet_preprocessing.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cache\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cache' is not defined"
     ]
    }
   ],
   "source": [
    "cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'psat_questions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jiwon/programming/ML/Deep daiv/Leetkiller/leet_preprocessing.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiwon/programming/ML/Deep%20daiv/Leetkiller/leet_preprocessing.ipynb#X25sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Extracting the data from chunks using the combined function\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiwon/programming/ML/Deep%20daiv/Leetkiller/leet_preprocessing.ipynb#X25sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m combined_json_data \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiwon/programming/ML/Deep%20daiv/Leetkiller/leet_preprocessing.ipynb#X25sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, chunk \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(psat_questions):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiwon/programming/ML/Deep%20daiv/Leetkiller/leet_preprocessing.ipynb#X25sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     extracted_data \u001b[39m=\u001b[39m combined_extract_from_chunk(chunk)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiwon/programming/ML/Deep%20daiv/Leetkiller/leet_preprocessing.ipynb#X25sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     problem_data \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiwon/programming/ML/Deep%20daiv/Leetkiller/leet_preprocessing.ipynb#X25sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m2023_PSAT_\u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiwon/programming/ML/Deep%20daiv/Leetkiller/leet_preprocessing.ipynb#X25sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mparagraph\u001b[39m\u001b[39m\"\u001b[39m: extracted_data[\u001b[39m\"\u001b[39m\u001b[39mparagraph\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiwon/programming/ML/Deep%20daiv/Leetkiller/leet_preprocessing.ipynb#X25sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m         }]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiwon/programming/ML/Deep%20daiv/Leetkiller/leet_preprocessing.ipynb#X25sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'psat_questions' is not defined"
     ]
    }
   ],
   "source": [
    "def combined_extract_from_chunk(chunk):\n",
    "    # Extract question\n",
    "    question_match = re.search(r\"(\\d+\\.\\s[^?]*\\?)\", chunk)\n",
    "    question = question_match.group(1) if question_match else None\n",
    "\n",
    "    # Extract choices\n",
    "    choices = re.findall(r\"(①[^②]+|②[^③]+|③[^④]+|④[^⑤]+|⑤[^\\n]+)\", chunk)\n",
    "    \n",
    "    # Extract paragraph, additional info and choices\n",
    "    if \"<보기>\" in question:\n",
    "        paragraph, rest = re.split(r\"<보  기>\", chunk.split(question)[1], maxsplit=1)\n",
    "        if \"①\" in rest:\n",
    "            additional_info, choices_text = re.split(r\"①\", rest, maxsplit=1)\n",
    "            additional_info = additional_info.strip()\n",
    "        else:\n",
    "            additional_info = rest.strip()\n",
    "    else:\n",
    "        paragraph = chunk.split(question)[1].split(\"①\")[0].strip()\n",
    "        additional_info = None\n",
    "\n",
    "    return {\n",
    "        \"question\": question.replace(\"<보기>\", \"\").strip(),\n",
    "        \"paragraph\": paragraph.strip(),\n",
    "        \"additional\": additional_info,\n",
    "        \"choices\": [choice.strip() for choice in choices]\n",
    "    }\n",
    "\n",
    "# Extracting the data from chunks using the combined function\n",
    "combined_json_data = []\n",
    "for idx, chunk in enumerate(psat_questions):\n",
    "    extracted_data = combined_extract_from_chunk(chunk)\n",
    "    problem_data = {\n",
    "        \"id\": f\"2023_PSAT_{idx + 1}\",\n",
    "        \"paragraph\": extracted_data[\"paragraph\"],\n",
    "        \"problems\": [{\n",
    "            \"question\": extracted_data[\"question\"],\n",
    "            \"choices\": extracted_data[\"choices\"]\n",
    "        }]\n",
    "    }\n",
    "    if extracted_data[\"additional\"]:\n",
    "        problem_data[\"problems\"][0][\"additional\"] = extracted_data[\"additional\"]\n",
    "    combined_json_data.append(problem_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEET data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hwp2Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import olefile\n",
    "import zlib\n",
    "import struct\n",
    "\n",
    "class HWPExtractor(object):\n",
    "    FILE_HEADER_SECTION = \"FileHeader\"\n",
    "    HWP_SUMMARY_SECTION = \"\\x05HwpSummaryInformation\"\n",
    "    SECTION_NAME_LENGTH = len(\"Section\")\n",
    "    BODYTEXT_SECTION = \"BodyText\"\n",
    "    HWP_TEXT_TAGS = [67]\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self._ole = self.load(filename)\n",
    "        self._dirs = self._ole.listdir()\n",
    "\n",
    "        self._valid = self.is_valid(self._dirs)\n",
    "        if (self._valid == False):\n",
    "            raise Exception(\"Not Valid HwpFile\")\n",
    "        \n",
    "        self._compressed = self.is_compressed(self._ole)\n",
    "        self.text = self._get_text()\n",
    "\t\n",
    "    # 파일 불러오기 \n",
    "    def load(self, filename):\n",
    "        return olefile.OleFileIO(filename)\n",
    "\t\n",
    "    # hwp 파일인지 확인 header가 없으면 hwp가 아닌 것으로 판단하여 진행 안함\n",
    "    def is_valid(self, dirs):\n",
    "        if [self.FILE_HEADER_SECTION] not in dirs:\n",
    "            return False\n",
    "\n",
    "        return [self.HWP_SUMMARY_SECTION] in dirs\n",
    "\n",
    "\t# 문서 포맷 압축 여부를 확인\n",
    "    def is_compressed(self, ole):\n",
    "        header = self._ole.openstream(\"FileHeader\")\n",
    "        header_data = header.read()\n",
    "        return (header_data[36] & 1) == 1\n",
    "\n",
    "\t# bodytext의 section들 목록을 저장\n",
    "    def get_body_sections(self, dirs):\n",
    "        m = []\n",
    "        for d in dirs:\n",
    "            if d[0] == self.BODYTEXT_SECTION:\n",
    "                m.append(int(d[1][self.SECTION_NAME_LENGTH:]))\n",
    "\n",
    "        return [\"BodyText/Section\"+str(x) for x in sorted(m)]\n",
    "\t\n",
    "    # text를 뽑아내는 함수\n",
    "    def get_text(self):\n",
    "        return self.text\n",
    "\n",
    "\t# 전체 text 추출\n",
    "    def _get_text(self):\n",
    "        sections = self.get_body_sections(self._dirs)\n",
    "        text = \"\"\n",
    "        for section in sections:\n",
    "            text += self.get_text_from_section(section)\n",
    "            text += \"\\n\"\n",
    "\n",
    "        self.text = text\n",
    "        return self.text\n",
    "\n",
    "\t# section 내 text 추출\n",
    "    def get_text_from_section(self, section):\n",
    "        bodytext = self._ole.openstream(section)\n",
    "        data = bodytext.read()\n",
    "\n",
    "        unpacked_data = zlib.decompress(data, -15) if self.is_compressed else data\n",
    "        size = len(unpacked_data)\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        text = \"\"\n",
    "        while i < size:\n",
    "            header = struct.unpack_from(\"<I\", unpacked_data, i)[0]\n",
    "            rec_type = header & 0x3ff\n",
    "            level = (header >> 10) & 0x3ff\n",
    "            rec_len = (header >> 20) & 0xfff\n",
    "\n",
    "            if rec_type in self.HWP_TEXT_TAGS:\n",
    "                rec_data = unpacked_data[i+4:i+4+rec_len]\n",
    "                text += rec_data.decode('utf-16')\n",
    "                text += \"\\n\"\n",
    "\n",
    "            i += 4 + rec_len\n",
    "\n",
    "        return text\n",
    "        \n",
    "# text 추출 함수 -> 이 함수를 사용하면 됨\n",
    "def get_text(filename):\n",
    "    hwp = HWPExtractor(filename) \n",
    "    return hwp.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Replace the old Chinese word with Korean word\n",
    "    text = text.replace(\"氠瑢\", \"빈칸\")\n",
    "    text = text.replace(\"敤敱\", \"π\")\n",
    "    \n",
    "    # Remove specific sequences\n",
    "    sequences_to_remove = [\"\\t\", \"\\x00\", \"\\x02\", \"\\x10\", \"\\x15\", \"\\x0b\", \"\\x0c\", \"Ȁ\", \"Ȱ\", \"צ\", \"ȶ\", \"ɞ\", \"ض\", \"ᧀ\", \"ˇ\", \"ᣣ\", \"ᣜ\", \"ฒ\", \"ᛩ\", \"빈칸\\r\\n\"]\n",
    "    for seq in sequences_to_remove:\n",
    "        text = text.replace(seq, \"\")\n",
    "    text = text.replace(\"Ā\", \" \")\n",
    "    \n",
    "    # Remove Chinese characters\n",
    "    text = re.sub(r'[\\u4e00-\\u9fff]+', '', text)\n",
    "    \n",
    "    # Define a regex pattern:\n",
    "    pattern = re.compile(\"[^가-힣0-9a-zA-Z!?#:<>()[]{};π∞'\\\".,\\-~ \\n①-⑮㉠-㉮△○~]\")\n",
    "    cleaned_text = pattern.sub(\"\", text)\n",
    "    \n",
    "    cleand_text = cleaned_text.replace(\"\\x1f\", \"\") # 물결 앞뒤고 \\x1f가 붙어있는 경우가 있음(미해결)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33760, 33207)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hwp_text), len(clean_leet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('이라는 한계 속에서 이루어지는 것임을 부정할 수 없기 때문이다. 뻔히 부적절한 결과가 예상되는 경우에도 문언에 구속될 것을 요구하는 것은 '\n",
      " '일견 합리적이지 않아 보일 수 있다. 그럼에도 불구하고 문언을 강조하는 입장은 ‘재량’이 연상시키는 ‘사람의 지배’에 대한 우려와, '\n",
      " '민주주의의 본질에 대한 성찰을 배경으로 하는 것임을 이해할 필요가 있다. 법률은 시민의 대표들이 지난한 타협의 과정 끝에 도출해 낸 '\n",
      " '결과물이다. 엄밀히 말해 오로지 법률의 문언 그 자체만이 민주적으로 결정된 것이며, 그 너머의 것에 대해서는, 심지어 입법 의도나 법률의 '\n",
      " '목적이라 해도 동등한 권위를 인정할 수 없다. 이러한 입장에서는 법률 적용의 결과가 부적절한지 여부보다 그것이 부적절하다고 결정할 수 '\n",
      " '있는 권한을 특정인에게 부여할 것인지 여부가 더 중요한 문제일 수 있다. 요컨대 해석자에게 그러한 권한을 부여하는 것이 바람직하지 않다고 '\n",
      " '생각하는 한, 비록 부적절한 결과가 예상되는 경우라 하더라도 여전히 문언에 구속될 것을 요구하는 편이 오히려 합리적일 수도 있는 '\n",
      " '것이다.\\r\\n'\n",
      " '28.윗글과 일치하는 것은?\\r\\n'\n",
      " '①\\x1e'\n",
      " '전통적인 법학방법론 학설의 입장에서는 결국 문언을 넘은 해석과 문언에 반하는 해석을 구별하지 않는다.\\r\\n'\n",
      " '②\\x1e'\n",
      " '종래의 법철학 학설 중 의미의 중심부와 주변부의 구별을 강조하는 입장에서는 해석에 있어 법률의 목적보다 문언에 주목한다.\\r\\n'\n",
      " '③\\x1e'\n",
      " '민주주의의 본질을 강조하는 입장에서는 비록 법률의 적용에 따른 것이라도 실질적으로 부적절한 결과를 인정할 수는 없다고 본다.\\r\\n'\n",
      " '④\\x1e'\n",
      " '법률 적용 결과의 합당성을 강조하는 입장에서는 문언이 제공하는 답이 부적절한지 여부는 해석자의 주관에 따라 달라질 수 있다고 '\n",
      " '주장한다.\\r\\n'\n",
      " '⑤\\x1e'\n",
      " '법학방법론과 법철학의 논의를 하나의 연결된 구성으로 제시하는 입장에서는 언어적 불확정성으로 인해 법률이 부적절한 답을 제공하는 사안에 '\n",
      " '주목한다.\\r\\n'\n",
      " '29.\\x0b'\n",
      " '漠杳\\x00\\x00\\x00\\x00\\x0b'\n",
      " '에 대한 진술로 가장 적절한 것은?\\r\\n'\n",
      " '판단하기 어려운 사안\\r\\n'\n",
      " '①\\x1e'\n",
      " '법률의 문언이 극도로 명확한 경우에는 판단하기 어려운 사안이 발생하지 않는다.\\r\\n'\n",
      " '②\\x1e'\n",
      " '판단하기 어려운 사안의 해석을 위해 법률의 목적에 구속되어야 하는 것은 아니다.\\r\\n'\n",
      " '③\\x1e'\n",
      " '문언을 넘은 해석은 문언이 해석자를 전혀 이끌어 주지 못할 때 비로소 시도될 수 있다.\\r\\n'\n",
      " '④\\x1e'\n",
      " '문언에 반하는 해석은 법률의 흠결이 있을 때 이를 보충하기 위한 것인 한 정당화될 수 있다.\\r\\n'\n",
      " '⑤\\x1e'\n",
      " '형식상 드러나 있는 법률의 흠결을 보충하기 위해서도 해당 법률의 본래적 구상보다는 전체 법질서를 고려한 해석이 필요하다.\\r\\n'\n",
      " '\\x0b'\n",
      " '漠杳\\x00\\x00\\x00\\x00\\x0b'\n",
      " '\\r\\n'\n",
      " '30.[A]의 입장에서 ㉠을 해석한 것으로 가장 적절한 것은?\\r\\n'\n",
      " '①\\x1e'\n",
      " '규칙의 목적이 야생의 생물 다양성을 보존하기 위한 것이라면, 멸종 위기 품종의 길고양이를 입양하는 것이 허용될 것이다.\\r\\n'\n",
      " '②\\x1e'\n",
      " '야성을 잃어버린 채 평생을 사람과 함께 산 사자가 ‘야생동물’의 언어적 의미에 부합한다면, 그것을 기르는 것도 허용되지 않을 '\n",
      " '것이다.\\r\\n'\n",
      " '③\\x1e'\n",
      " '규칙의 목적이 주민의 안전을 확보하는 것이라면, 길들여지지 않는 야수의 공격성을 지닌 들개를 기르는 것이 금지될 수도 있을 것이다.\\r\\n'\n",
      " '④\\x1e'\n",
      " '인근에서 잡힌 희귀한 개구리를 관상용으로 키우는 것이 허용되었다면, ‘야생동물’의 언어적 의미를 주거에 두고 감상하기에 적합하지 않은 '\n",
      " '동물로 보았을 것이다.\\r\\n'\n",
      " '⑤\\x1e'\n",
      " '여러 종류의 야생동물의 유전자를 조합하여 실험실에서 창조한 동물을 기르는 것이 금지되었다면, ‘야생동물’의 언어적 의미를 자연에서 태어나 '\n",
      " '살아가는 동물로 보았을 것이다.\\r\\n'\n",
      " '\\x0b'\n",
      " '氠瑢\\x00\\x00\\x00\\x00\\x0b'\n",
      " '\\r\\n'\n",
      " '\\x1f* 확인 사항\\r\\n'\n",
      " '◦\\x1f문제지와 답안지의 해당란에 필요한 내용을 정확하게 표기했는지\\n'\n",
      " '확인하십시오.\\r\\n'\n",
      " '\\n')\n"
     ]
    }
   ],
   "source": [
    "hwp_text = get_text(os.path.join(file_path, 'LEET_2021_L(E).hwp'))\n",
    "pprint.pprint(hwp_text[32000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('이다.\\r\\n'\n",
      " '28.윗글과 일치하는 것은?\\r\\n'\n",
      " '①\\x1e'\n",
      " '전통적인 법학방법론 학설의 입장에서는 결국 문언을 넘은 해석과 문언에 반하는 해석을 구별하지 않는다.\\r\\n'\n",
      " '②\\x1e'\n",
      " '종래의 법철학 학설 중 의미의 중심부와 주변부의 구별을 강조하는 입장에서는 해석에 있어 법률의 목적보다 문언에 주목한다.\\r\\n'\n",
      " '③\\x1e'\n",
      " '민주주의의 본질을 강조하는 입장에서는 비록 법률의 적용에 따른 것이라도 실질적으로 부적절한 결과를 인정할 수는 없다고 본다.\\r\\n'\n",
      " '④\\x1e'\n",
      " '법률 적용 결과의 합당성을 강조하는 입장에서는 문언이 제공하는 답이 부적절한지 여부는 해석자의 주관에 따라 달라질 수 있다고 '\n",
      " '주장한다.\\r\\n'\n",
      " '⑤\\x1e'\n",
      " '법학방법론과 법철학의 논의를 하나의 연결된 구성으로 제시하는 입장에서는 언어적 불확정성으로 인해 법률이 부적절한 답을 제공하는 사안에 '\n",
      " '주목한다.\\r\\n'\n",
      " '29.에 대한 진술로 가장 적절한 것은?\\r\\n'\n",
      " '판단하기 어려운 사안\\r\\n'\n",
      " '①\\x1e'\n",
      " '법률의 문언이 극도로 명확한 경우에는 판단하기 어려운 사안이 발생하지 않는다.\\r\\n'\n",
      " '②\\x1e'\n",
      " '판단하기 어려운 사안의 해석을 위해 법률의 목적에 구속되어야 하는 것은 아니다.\\r\\n'\n",
      " '③\\x1e'\n",
      " '문언을 넘은 해석은 문언이 해석자를 전혀 이끌어 주지 못할 때 비로소 시도될 수 있다.\\r\\n'\n",
      " '④\\x1e'\n",
      " '문언에 반하는 해석은 법률의 흠결이 있을 때 이를 보충하기 위한 것인 한 정당화될 수 있다.\\r\\n'\n",
      " '⑤\\x1e'\n",
      " '형식상 드러나 있는 법률의 흠결을 보충하기 위해서도 해당 법률의 본래적 구상보다는 전체 법질서를 고려한 해석이 필요하다.\\r\\n'\n",
      " '\\r\\n'\n",
      " '30.[A]의 입장에서 ㉠을 해석한 것으로 가장 적절한 것은?\\r\\n'\n",
      " '①\\x1e'\n",
      " '규칙의 목적이 야생의 생물 다양성을 보존하기 위한 것이라면, 멸종 위기 품종의 길고양이를 입양하는 것이 허용될 것이다.\\r\\n'\n",
      " '②\\x1e'\n",
      " '야성을 잃어버린 채 평생을 사람과 함께 산 사자가 ‘야생동물’의 언어적 의미에 부합한다면, 그것을 기르는 것도 허용되지 않을 '\n",
      " '것이다.\\r\\n'\n",
      " '③\\x1e'\n",
      " '규칙의 목적이 주민의 안전을 확보하는 것이라면, 길들여지지 않는 야수의 공격성을 지닌 들개를 기르는 것이 금지될 수도 있을 것이다.\\r\\n'\n",
      " '④\\x1e'\n",
      " '인근에서 잡힌 희귀한 개구리를 관상용으로 키우는 것이 허용되었다면, ‘야생동물’의 언어적 의미를 주거에 두고 감상하기에 적합하지 않은 '\n",
      " '동물로 보았을 것이다.\\r\\n'\n",
      " '⑤\\x1e'\n",
      " '여러 종류의 야생동물의 유전자를 조합하여 실험실에서 창조한 동물을 기르는 것이 금지되었다면, ‘야생동물’의 언어적 의미를 자연에서 태어나 '\n",
      " '살아가는 동물로 보았을 것이다.\\r\\n'\n",
      " '\\x1f* 확인 사항\\r\\n'\n",
      " '◦\\x1f문제지와 답안지의 해당란에 필요한 내용을 정확하게 표기했는지\\n'\n",
      " '확인하십시오.\\r\\n'\n",
      " '\\n')\n"
     ]
    }
   ],
   "source": [
    "clean_leet_text = clean_text(hwp_text)\n",
    "pprint.pprint(clean_leet_text[32000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hwp2PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import win32com.client as win32\n",
    "import win32gui\n",
    "\n",
    "os.chdir(file_path)\n",
    "\n",
    "hwp = win32.gencache.EnsureDispatch(\"HWPFrame.HwpObject\")\n",
    "hwnd = win32gui.FindWindow(None, \"빈 문서 1 - 한글\")\n",
    "\n",
    "win32gui.ShowWindow(hwnd, 0)\n",
    "hwp.RegisterModule(\"FilePathCheckDLL\", \"FilePathCheckerModule\")\n",
    "\n",
    "for i in file_name:\n",
    "    hwp.Open(os.path.join(file_path, i))  # 한/글로 열어서\n",
    "    hwp.HAction.GetDefault('FileSaveAsPdf', hwp.HParameterSet.HFileOpenSave.HSet)  # PDF로 저장할 건데, 설정값은 아래와 같이.\n",
    "    hwp.HParameterSet.HFileOpenSave.filename = os.path.join(file_path, i.replace('.hwp', 'pdf'))  # 확장자는 .pdf로,\n",
    "    hwp.HParameterSet.HFileOpenSave.Format = 'PDF'  # 포맷은 PDF로,\n",
    "    hwp.HAction.Execute('FileSaveAsPdf', hwp.HParameterSet.HFileOpenSave.HSet) \n",
    "    \n",
    "win32gui.ShowWindow(hwnd, 5)\n",
    "hwp.XHwpDocuments.Close(isDirty=False)\n",
    "hwp.Quit()\n",
    "\n",
    "del hwp\n",
    "del win32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF2Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
