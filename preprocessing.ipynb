{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSAT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2 pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF2Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LEET_2021_L.hwp', 'LEET_2021_L(E).hwp', 'PSAT_2023_L.hwp', 'PSAT_2023.pdf']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "file_path = os.path.join(os.getcwd(), 'Data')\n",
    "file_name = os.listdir(file_path)\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_psat_text(file_name):\n",
    "    psat_text = []\n",
    "    for file in file_name:\n",
    "        if file.endswith('.pdf'):\n",
    "            pdf = PdfReader(os.path.join(file_path, file))\n",
    "            text = ''\n",
    "            \n",
    "            for i, page in enumerate(pdf.pages):\n",
    "                text += page.extract_text()\n",
    "            \n",
    "            text = text.replace(' .', '.')\n",
    "            text = text.replace(' , ', ', ')\n",
    "            text = text.replace(' ? ', '? ')\n",
    "            text = re.sub(r\"(\\d+)\\.\", r\"\\1. \", text)\n",
    "            text = re.sub(r\"(①)|(②)|(③)|(④)|(⑤)\", r\"\\1\\2\\3\\4\\5 \", text)\n",
    "\n",
    "            psat_text.append(text)\n",
    "\n",
    "    return psat_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "psat_text = clean_psat_text(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('C를 파견한다.\\n'\n",
      " '③ C를 파견하 지 않으면 D를 파견하 지 않는다.\\n'\n",
      " '④ C를 파견하 지 않으면 E를 파견하 지 않는다.\\n'\n",
      " '⑤ D나 E를 파견하 면 C를 파견한다.16. 다음 글의 내용이 참일 때 반드시 참인 것은?\\n'\n",
      " '  영어 회화가 가능한 갑순과 을돌, 중국어 회화가 가능한 병수와 \\n'\n",
      " '정희를 다음 <배치 원칙>에 따라 총무부, 인사부, 영업부, \\n'\n",
      " '자재부에 각 한 명씩 모두 배치하기로 하였다. 네 명 중 병수를 \\n'\n",
      " '제외한 나머지는 신입사원이고, 갑순만 공인노무사 자격증을 \\n'\n",
      " '갖고 있다.\\n'\n",
      " '<배치 원칙>\\n'\n",
      " '○총무부와 인사부 중 한 곳에는 공인노무사 자격증을 갖고 \\n'\n",
      " '있는 사원을 배치한다.\\n'\n",
      " '○영업부와 자재부 중 한 곳에만 중국어 회화 가능자를 배치\\n'\n",
      " '한다.\\n'\n",
      " '○정희를 인사부에도 자재부에도 배치하지 않는다면, 영업부에 \\n'\n",
      " '배치한다.\\n'\n",
      " '○영업부와 자재부 중 한 곳에만 신입사원을 배치한다.\\n'\n",
      " '  이 원칙에 따라 부서를 배치한 결과 일부 사원의 부서만 \\n'\n",
      " '결정되었다. 이에 다음의 원칙을 추가하였다.\\n'\n",
      " '<추가 원칙>\\n'\n",
      " '○인사부와 영업부에 같은 외국어 회화를 할 수 있는 사원들을 \\n'\n",
      " '배치한다.\\n'\n",
      " '  그 결과 <배치 원칙>을 어기지 않으면서 위 네 명의 배치를 \\n'\n",
      " '다 결정할 수 있었다.\\n'\n",
      " '① <배치 원칙>만으로 배치된 갑순의 부서는 영업부이다.\\n'\n",
      " '② <배치 원칙>만으로 배치된 을돌의 부서는 자재부이다.\\n'\n",
      " '③ <배치 원칙>과 <추가 원칙>에 따라 최종적으로 배치된 병수의 \\n'\n",
      " '부서는 자재부이다.\\n'\n",
      " '④ <배치 원칙>과 <추가 원칙>에 따라 최종적으로 배치된 정희의 \\n'\n",
      " '부서는 인사부이다.\\n'\n",
      " '⑤ <배치 원칙>과 <추가 원칙>에 따라 최종적으로 배치된 갑순의 \\n'\n",
      " '부서도 을돌의 부서도 총무부가 아니다.2023년도 국가공무원 5급 공채 등 필기시험 언어논리영역 가책형 9쪽\\n'\n",
      " '17. 다음 글의 A와 B에 대한 분석으로 적절한 것만을 <보기>에서 모두 \\n'\n",
      " '고르면 ?\\n'\n",
      " '  유행이란 어떤 새로운 양식이나 현상이 사회에 널리 퍼지는 \\n'\n",
      " '경향을 의미한다. 유행은 특정한 취향과 기호가 사회 구성원 \\n'\n",
      " '다수의 승인을 받아 사회 저변으로 확대되는 과정에서 형성된다. \\n'\n",
      " '이러한 유행의 형성 원인을 두고 다음의 두 견해가 있다.\\n'\n",
      " 'A:유행은 개인의 취향과 기호를 이용하는 산업 자본에 의해 \\n'\n",
      " '기획되고 만들어진 것이다. 패션쇼나 전시회 등으로 올해의 \\n'\n",
      " '유행 상품을 만들어낸 기업은 그 상품을 시장에 선보이기 \\n'\n",
      " '무섭게 바로 내년에 유행시킬 상품을 준비한다. 개인은 \\n'\n",
      " '자신의 취향이나 기호에 따라 어떤 상품을 선택했다고 \\n'\n",
      " '착각할 수 있지만 실은 선택해야 할 상품을 기업이 이미 \\n'\n",
      " '정해 놓은 것이다. 어떤 유행이 오랜 기간 지속되면 기업은 \\n'\n",
      " '이윤이 줄어들 수밖에 없으므로, 기업은 주기적으로 새로운 \\n'\n",
      " '유행을 만들어낸다. 더 나아가 기업은 미디어를 적극 \\n'\n",
      " '활용하여 유행의 변화 속도를 과거보다 더 빠르게 만들었다.\\n'\n",
      " 'B:소비자는 자기의 취향과 기호에 의해 상품을 주체적으로 \\n'\n",
      " '선택한다고 믿지만 실제로는 그렇지 않다. 실상은 다른 \\n'\n",
      " '사람들과 같아지지 않으면 준거집단에서 소외되어 따돌림\\n'\n",
      " '당할지도 모른다는 불안이 상품을 선택하고 소비하게 \\n'\n",
      " '만든다. 소외에 대한 이러한 불안은 소비자들로 하여금 \\n'\n",
      " '자신의 주변에서 무슨 일이 벌어지고 있는지를 주목하게 \\n'\n",
      " '한다. 나아가 그렇게 주목한 것들을 추종하고 모방하여 \\n'\n",
      " '소비하도록 부추긴다. 바로 이와 같은 과정을 거쳐서 \\n'\n",
      " '결과적으로 유행이 형성되는 것이다.\\n'\n",
      " '<보  기>\\n'\n",
      " 'ㄱ.A도 B도 유행의 형성 원인이 소비자 개인의 취향과 기호에 \\n'\n",
      " '의한 주체적 상품 선택이라고 보지 않는다.\\n'\n",
      " 'ㄴ.B와 달리 A는 소비자들의 모방 심리가 유행에 영향을 \\n'\n",
      " '미치지 않는다고 주장한다.\\n'\n",
      " 'ㄷ.A보다 B가 사회에서 유행의 발생과 변화 속도를 더 잘 \\n'\n",
      " '설명할 수 있다.\\n'\n",
      " '① ㄱ\\n'\n",
      " '② ㄷ\\n'\n",
      " '③ ㄱ, ㄴ\\n'\n",
      " '④ ㄴ, ㄷ\\n'\n",
      " '⑤ ㄱ, ㄴ, ㄷ18. 다음 갑과 을의 논쟁에 대한 평가로 적절한 것만을 <보기>에서 모두 \\n'\n",
      " '고르면 ?\\n'\n",
      " '갑:유전자는 자신의 복제본을 더 많이 남기기 위하여 유기체를 \\n'\n",
      " '활용한다. 그러므로 유기체는 유전자를 실어 나르는 운반체에 \\n'\n",
      " '불과하다. 유기체는 유전자의 이익을 위하여 행동한다. \\n'\n",
      " '유기체의 행동 방식은 유전자를 최대한으로 퍼뜨리기 위한 \\n'\n",
      " '전략적 선택')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(psat_text[0][18000:20000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- '2023년도 국가공무원 5급 공채 등 필기시험 언어논리영역 가책형 n쪽' 삭제\n",
    "- `text = re.sub(r\"(\\d+)\\.\", r\"\\1. \", text)`: 1~9만 가능, 여기 조건에 숫자 더 늘려야함\n",
    "\n",
    "- 7번: \\ue0ac -> π"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEET data(Unsettled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hwp2Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import olefile\n",
    "import zlib\n",
    "import struct\n",
    "\n",
    "class HWPExtractor(object):\n",
    "    FILE_HEADER_SECTION = \"FileHeader\"\n",
    "    HWP_SUMMARY_SECTION = \"\\x05HwpSummaryInformation\"\n",
    "    SECTION_NAME_LENGTH = len(\"Section\")\n",
    "    BODYTEXT_SECTION = \"BodyText\"\n",
    "    HWP_TEXT_TAGS = [67]\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self._ole = self.load(filename)\n",
    "        self._dirs = self._ole.listdir()\n",
    "\n",
    "        self._valid = self.is_valid(self._dirs)\n",
    "        if (self._valid == False):\n",
    "            raise Exception(\"Not Valid HwpFile\")\n",
    "        \n",
    "        self._compressed = self.is_compressed(self._ole)\n",
    "        self.text = self._get_text()\n",
    "\t\n",
    "    # 파일 불러오기 \n",
    "    def load(self, filename):\n",
    "        return olefile.OleFileIO(filename)\n",
    "\t\n",
    "    # hwp 파일인지 확인 header가 없으면 hwp가 아닌 것으로 판단하여 진행 안함\n",
    "    def is_valid(self, dirs):\n",
    "        if [self.FILE_HEADER_SECTION] not in dirs:\n",
    "            return False\n",
    "\n",
    "        return [self.HWP_SUMMARY_SECTION] in dirs\n",
    "\n",
    "\t# 문서 포맷 압축 여부를 확인\n",
    "    def is_compressed(self, ole):\n",
    "        header = self._ole.openstream(\"FileHeader\")\n",
    "        header_data = header.read()\n",
    "        return (header_data[36] & 1) == 1\n",
    "\n",
    "\t# bodytext의 section들 목록을 저장\n",
    "    def get_body_sections(self, dirs):\n",
    "        m = []\n",
    "        for d in dirs:\n",
    "            if d[0] == self.BODYTEXT_SECTION:\n",
    "                m.append(int(d[1][self.SECTION_NAME_LENGTH:]))\n",
    "\n",
    "        return [\"BodyText/Section\"+str(x) for x in sorted(m)]\n",
    "\t\n",
    "    # text를 뽑아내는 함수\n",
    "    def get_text(self):\n",
    "        return self.text\n",
    "\n",
    "\t# 전체 text 추출\n",
    "    def _get_text(self):\n",
    "        sections = self.get_body_sections(self._dirs)\n",
    "        text = \"\"\n",
    "        for section in sections:\n",
    "            text += self.get_text_from_section(section)\n",
    "            text += \"\\n\"\n",
    "\n",
    "        self.text = text\n",
    "        return self.text\n",
    "\n",
    "\t# section 내 text 추출\n",
    "    def get_text_from_section(self, section):\n",
    "        bodytext = self._ole.openstream(section)\n",
    "        data = bodytext.read()\n",
    "\n",
    "        unpacked_data = zlib.decompress(data, -15) if self.is_compressed else data\n",
    "        size = len(unpacked_data)\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        text = \"\"\n",
    "        while i < size:\n",
    "            header = struct.unpack_from(\"<I\", unpacked_data, i)[0]\n",
    "            rec_type = header & 0x3ff\n",
    "            level = (header >> 10) & 0x3ff\n",
    "            rec_len = (header >> 20) & 0xfff\n",
    "\n",
    "            if rec_type in self.HWP_TEXT_TAGS:\n",
    "                rec_data = unpacked_data[i+4:i+4+rec_len]\n",
    "                text += rec_data.decode('utf-16')\n",
    "                text += \"\\n\"\n",
    "\n",
    "            i += 4 + rec_len\n",
    "\n",
    "        return text\n",
    "        \n",
    "# text 추출 함수 -> 이 함수를 사용하면 됨\n",
    "def get_text(filename):\n",
    "    hwp = HWPExtractor(filename) \n",
    "    return hwp.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Replace the old Chinese word with Korean word\n",
    "    text = text.replace(\"氠瑢\", \"빈칸\")\n",
    "    text = text.replace(\"敤敱\", \"π\")\n",
    "    \n",
    "    # Remove specific sequences\n",
    "    sequences_to_remove = [\"\\t\", \"\\x00\", \"\\x02\", \"\\x10\", \"\\x15\", \"\\x0b\", \"\\x0c\", \"Ȁ\", \"Ȱ\", \"צ\", \"ȶ\", \"ɞ\", \"ض\", \"ᧀ\", \"ˇ\", \"ᣣ\", \"ᣜ\", \"ฒ\", \"ᛩ\", \"빈칸\\r\\n\"]\n",
    "    for seq in sequences_to_remove:\n",
    "        text = text.replace(seq, \"\")\n",
    "    text = text.replace(\"Ā\", \" \")\n",
    "    \n",
    "    # Remove Chinese characters\n",
    "    text = re.sub(r'[\\u4e00-\\u9fff]+', '', text)\n",
    "    \n",
    "    # Define a regex pattern:\n",
    "    pattern = re.compile(\"[^가-힣0-9a-zA-Z!?#:<>()[]{};π∞'\\\".,\\-~ \\n①-⑮㉠-㉮△○~]\")\n",
    "    cleaned_text = pattern.sub(\"\", text)\n",
    "    \n",
    "    cleand_text = cleaned_text.replace(\"\\x1f\", \"\") # 물결 앞뒤고 \\x1f가 붙어있는 경우가 있음(미해결)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hwp2PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import win32com.client as win32\n",
    "import win32gui\n",
    "\n",
    "os.chdir(file_path)\n",
    "\n",
    "hwp = win32.gencache.EnsureDispatch(\"HWPFrame.HwpObject\")\n",
    "hwnd = win32gui.FindWindow(None, \"빈 문서 1 - 한글\")\n",
    "\n",
    "win32gui.ShowWindow(hwnd, 0)\n",
    "hwp.RegisterModule(\"FilePathCheckDLL\", \"FilePathCheckerModule\")\n",
    "\n",
    "for i in file_name:\n",
    "    hwp.Open(os.path.join(file_path, i))  # 한/글로 열어서\n",
    "    hwp.HAction.GetDefault('FileSaveAsPdf', hwp.HParameterSet.HFileOpenSave.HSet)  # PDF로 저장할 건데, 설정값은 아래와 같이.\n",
    "    hwp.HParameterSet.HFileOpenSave.filename = os.path.join(file_path, i.replace('.hwp', 'pdf'))  # 확장자는 .pdf로,\n",
    "    hwp.HParameterSet.HFileOpenSave.Format = 'PDF'  # 포맷은 PDF로,\n",
    "    hwp.HAction.Execute('FileSaveAsPdf', hwp.HParameterSet.HFileOpenSave.HSet) \n",
    "    \n",
    "win32gui.ShowWindow(hwnd, 5)\n",
    "hwp.XHwpDocuments.Close(isDirty=False)\n",
    "hwp.Quit()\n",
    "\n",
    "del hwp\n",
    "del win32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF2Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
